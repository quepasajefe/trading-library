# Investigating - 2025 Model Series Lecture 07
**Date Processed:** [Current Date]  
**Lecture Type:** Practical Application  
**Focus:** How to Investigate and Document Algorithmic Signatures

## The Philosophy of Backtesting: Building Pattern Recognition

Zeussy challenges the common approach to backtesting where traders use replay tools to go candle by candle trying to predict what happens next in historical data. This method fails because it attempts to simulate live trading rather than building pattern recognition. The fundamental error is treating backtesting as practice trading rather than data collection.

The correct approach treats backtesting as a data collecting tool designed to train your eye to see algorithmic signatures. The goal isn't to prove you can trade historical data but to build a database of repeating phenomena within price delivery. This volume-based approach - collecting many examples of the same signatures - develops the pattern recognition necessary for live market application.

This philosophical shift transforms backtesting from an ego exercise ("look how well I can trade history") to a learning exercise ("let me document how algorithms behave"). You're not trying to make money on past data; you're trying to understand the mechanics that will help you recognize opportunities in future data.

## The Investigation Framework

### Step 1: Determine Higher Time Frame Institutional Order Flow

The investigation always begins with establishing whether institutional order flow is bullish or bearish on higher timeframes. Without this context, lower timeframe analysis becomes meaningless noise. In the example, Zeussy had been bearish on indices for months, providing the directional bias for all subsequent analysis.

This isn't about predicting direction but recognizing the current algorithmic program. Once identified, every subsequent analysis filters through this lens. In a sell program, you're looking for shorting opportunities at premium arrays. In a buy program, you're looking for longs at discount arrays. The higher timeframe program determines everything about how you interpret lower timeframe setups.

### Step 2: Identify Key Reference Points

The investigation focuses on three primary reference points:

**Previous Month's High and Low:** These become the primary draws on liquidity and points of interest for the current month. In the example, January's high and low became February's key reference points.

**Key Price Levels:** The mathematical levels (like 19,000, 19,500 on Nasdaq) that algorithms reference as they work through dealing ranges.

**Time Cycle Boundaries:** Session highs and lows (Asia, London, New York AM) that create temporal reference points for algorithmic decisions.

These aren't separate elements but convergent references that algorithms use simultaneously. When multiple reference points align, the probability of algorithmic reaction increases dramatically.

### Step 3: Document Everything Systematically

Zeussy demonstrates using a Notion database to systematically log:
- Date and day of week
- Market (Nasdaq in examples)
- Session (New York AM, London, etc.)
- Timeframe charts (Daily, Hourly, M15)
- Key levels and their reactions
- Time cycle influences
- Manipulation vs distribution phases

This systematic documentation isn't bureaucracy but pattern building. Each logged example adds to your database of how algorithms behave around specific conditions. Over time, patterns emerge that wouldn't be visible from isolated examples.

## Real Market Examples: Monday's Analysis

### The Setup Recognition

On Monday, Zeussy identified 19,000 as the key objective. The investigation revealed:
- Asia engineered sell-side liquidity above 19,000
- London low also formed above 19,000
- Both sessions respected the level without touching it

This liquidity engineering above a key level signals algorithmic preparation. When multiple sessions engineer liquidity above the same level without reaching it, algorithms are building the conditions for eventual delivery to that level.

### The Manipulation Phase

New York opened low and dropped into 19,000 - this entire move from 7 AM to the absolute low represents manipulation. The key insight: manipulation isn't random selling but algorithmic positioning before reversal. The wick below 19,000 followed by immediate reversal confirms this was a liquidity grab, not a breakdown.

This manipulation phase is essential for the subsequent distribution higher. Without grabbing sell-side liquidity below 19,000, algorithms lack the fuel for the rally. The manipulation provides both the liquidity and the trapped traders necessary for efficient distribution in the opposite direction.

### The Power of Convergence

The Monday example shows three elements converging:
1. Key level (19,000)
2. Time cycles (Asia low, London low, NY manipulation)
3. Liquidity engineering (sell-side below the level)

When these elements align, you're not hoping for a reversal - you're identifying where algorithms are programmed to reverse. This convergence transforms subjective analysis into objective recognition of algorithmic behavior.

## Real Market Examples: Tuesday's Analysis

### Continuation vs Reversal Recognition

Tuesday's analysis demonstrates how to recognize whether a program continues or reverses. The key indicator was a daily FVG (fair value gap) from Monday. As long as price didn't displace below this FVG, the expectation was continuation higher toward 19,500.

This shows how PD arrays function as program validators. The FVG isn't just support - it's an algorithmic marker that confirms the current program remains valid. Displacement below would signal program change; respect of the level confirms continuation.

### Multi-Level Confluence

The 19,500 level attracted price because of multiple factors:
- Monday stopped just below it (engineered buy-side liquidity)
- Daily FVG aligned with the level
- Previous day high was taken out accessing more liquidity
- SMT (smart money divergence) formed with ES

This multi-factor confluence at 19,500 created a high-probability reversal point. Each factor alone might be insignificant, but together they create overwhelming algorithmic significance.

### The Complete Market Maker Sell Model

Tuesday's high at 19,500 contained a complete market maker sell model within just three hourly candles. The entire rally was manipulation - engineering liquidity by trapping buyers who believed the breakout above the previous day's high was bullish. The reversal from 19,500 with SMT confirmation revealed the true algorithmic intent.

This demonstrates the fractal nature in real-time: what appears as a simple reversal on the hourly chart contains a complete algorithmic program on lower timeframes. Every swing point is "absolutely algorithmically driven" and can be anticipated when you understand the framework.

## Session Analysis Methodology

### Categorizing Session Behavior

Zeussy demonstrates categorizing each session's behavior:
- **Asia:** Consolidation (engineering liquidity)
- **London:** Expansion (both directions - up then down)
- **New York AM:** Distribution (trending move)

This categorization reveals patterns in how algorithms distribute functions across sessions. Asia often engineers, London often manipulates, New York often distributes. Understanding these tendencies helps anticipate which session will provide the cleanest opportunities.

### Why Avoid Asia Session

Despite the concepts working across all sessions, Zeussy specifically discourages trading Asia session for Western markets. The delivery isn't as clean because Asia serves primarily to engineer liquidity for subsequent sessions rather than distribute price efficiently.

This is a practical consideration: you want to trade where algorithms execute their primary programs, not where they prepare for execution. London and New York sessions show cleaner algorithmic signatures because that's where the primary distribution occurs for Western markets.

## The Core Principle: Recognizing Program States

### The Only Two Variables That Matter

Zeussy reveals a fundamental simplification: "All that matters is that you recognize sell and buy program. Sell and buy program - that's the only two variables which you need to know."

This binary framework cuts through complexity:
- **In sell programs:** Every premium array functions as resistance
- **In buy programs:** Every discount array functions as support

This principle transforms complex analysis into simple recognition. You don't need to evaluate every pattern, indicator, or level. First identify the program, then everything else follows automatically. Premium arrays in sell programs are shorting opportunities. Discount arrays in buy programs are long opportunities. The program state determines the function of every level.

## Practical Tools and Resources

### The Time Cycles Indicator

The green boxes shown in examples are plotted by the time cycles indicator, automatically marking session boundaries and 90-minute cycles. This tool eliminates manual time marking and ensures consistent analysis across all charts.

The indicator revealed how price reached the weekly FVG exactly as the AM high formed at 10-11:30 AM cycle high, then rolled over at 11:30 AM lunch opening. This precise time-price convergence would be difficult to spot without systematic time marking.

### The Investigation Process

The practical process demonstrated:
1. Screenshot higher timeframe context (daily showing monthly references)
2. Drop to hourly to identify session-based opportunities
3. Document in Notion with all relevant details
4. Focus on swing point recognition rather than entry precision
5. Build volume of examples rather than perfect individual trades

This systematic approach builds pattern recognition through repetition rather than analysis paralysis on individual setups.

## Critical Learning Points

### Focus on Swing Recognition First

Zeussy emphasizes that everything taught so far relates to recognizing swing points - identifying when programs change from sell to buy or vice versa. This is more important than precise entry techniques or lower timeframe tactics.

Master the ability to identify "Are we now changing from sell to buy program or from buy to sell program?" before diving into execution details. The lower timeframe signatures come later; first develop the ability to read program transitions on higher timeframes.

### The Hourly Chart Sufficiency

The examples prove that even from just the hourly chart, you can identify lower timeframe opportunities. You don't need multiple monitors with dozens of timeframes. A clean hourly chart showing key levels, time cycles, and PD arrays provides sufficient information to identify where market maker models will form on lower timeframes.

This simplification is liberating - you don't need complex multi-timeframe analysis to find opportunities. Understand the framework on higher timeframes, and you know where to look on lower timeframes when the time comes for execution.

## Questions for Further Investigation

Several areas warrant additional investigation:

**How do we definitively determine the institutional order flow direction?** Zeussy mentions "there's a lot which we can discuss" but doesn't provide the complete methodology.

**What constitutes SMT (smart money divergence) between correlated markets?** This concept was mentioned but not explained in detail.

**How do we determine which key levels become objectives?** Why 19,000 and 19,500 specifically?

**What makes delivery "clean" versus "not clean"?** Subjective assessment or objective criteria?

**How many examples constitute sufficient pattern recognition?** When do you have "enough" data?

## The Path Forward

This lecture transforms theoretical knowledge into practical application. The framework is clear: determine the program, identify convergence of time and price references, document systematically, and build pattern recognition through volume of examples.

The emphasis on investigation over trading, on pattern recognition over prediction, and on systematic documentation over random chart viewing provides a professional approach to market study. This isn't about finding the perfect setup but about understanding the algorithmic language through repeated observation.

The simplification to just recognizing buy versus sell programs, combined with the principle that program state determines array function, makes the complex appear simple. When you know the program, you know how every level will behave. The investigation process builds the pattern recognition to identify programs in real-time, transforming hindsight into foresight through systematic study.

---

## Personal Investigation Notes
*[To be filled during chart study and validation]*

### Investigation Log Template:
- Date/Day:
- Market:
- Session:
- HTF Order Flow:
- Key Levels:
- Time Cycle Influences:
- Manipulation Phase:
- Distribution Phase:
- Program Recognition:

### Patterns Observed:

### Questions for Forum: